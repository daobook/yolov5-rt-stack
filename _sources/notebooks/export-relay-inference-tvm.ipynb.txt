{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在 TVM 上部署 yolort\n",
    "\n",
    "本文是使用 Relay VM 部署 PyTorch YOLOv5 模型的介绍性教程。\n",
    "\n",
    "首先应该安装 PyTorch。TorchVision 也是必需的，因为将使用它作为模型动物园。\n",
    "\n",
    "快速解决方案：\n",
    "\n",
    "```shell\n",
    "pip install torch==1.10.1\n",
    "pip install torchvision==0.11.2\n",
    "```\n",
    "\n",
    "或者参考官方教程：\n",
    "https://pytorch.org/get-started/locally/\n",
    "\n",
    "PyTorch 版本应该向后兼容，但应该与正确的 TorchVision 版本一起使用。\n",
    "\n",
    "目前，仅用 PyTorch 1.7.x 和 1.10.x 测试 `TVM`。其他版本可能不稳定。\n",
    "\n",
    "这个笔记本是用 macOS M1 运行的。\n",
    "\n",
    "---\n",
    "\n",
    "版权所有 © 大多数代码复制自 [TVM 教程](https://tvm.apache.org/docs/tutorials/frontend/deploy_object_detection_pytorch.html#sphx-glr-tutorials-frontend-deploy-object-detection-pytorch-py)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 TVM\n",
    "from tvm_book.tvm.env import set_mxnet, set_tvm, set_cudnn\n",
    "# TVM_ROOT = \"/media/pc/data/4tb/zzy/zzy/npu/tvm\"\n",
    "TVM_ROOT = \"/media/pc/data/4tb/lxw/tvm\"\n",
    "TVM_ROOT = \"/media/pc/data/4tb/lxw/books/tvm\"\n",
    "set_tvm(TVM_ROOT)\n",
    "set_mxnet()\n",
    "set_cudnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.runtime.vm import VirtualMachine\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练的 `yolov5n` 模型并追踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 640\n",
    "input_shape = (in_size, in_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolort.models import yolov5n\n",
    "from yolort.relay import get_trace_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func = yolov5n(pretrained=True, size=(in_size, in_size))\n",
    "script_module = get_trace_module(model_func, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.yolort.relay.trace_wrapper.TraceWrapper,\n",
       "      %images : Float(1, 3, 640, 640, strides=[1228800, 409600, 640, 1], requires_grad=0, device=cpu)):\n",
       "  %4653 : __torch__.yolort.models.yolov5.YOLOv5 = prim::GetAttr[name=\"model\"](%self.1)\n",
       "  %5021 : (Tensor, Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%4653, %images)\n",
       "  %5018 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), %5019 : Float(0, strides=[1], requires_grad=0, device=cpu), %5020 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%5021)\n",
       "  %3799 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu), Long(0, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%5018, %5019, %5020)\n",
       "  return (%3799)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_module.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载测试图片并预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolort.utils import get_image_from_url\n",
    "\n",
    "img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/bus.jpg\"\n",
    "# img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/zidane.jpg\"\n",
    "img = get_image_from_url(img_source)\n",
    "\n",
    "img = img.astype(\"float32\")\n",
    "img = cv2.resize(img, (in_size, in_size))\n",
    "\n",
    "img = np.transpose(img / 255.0, [2, 0, 1])\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入 graph 到 Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, (1, 3, *input_shape))]\n",
    "mod, params = relay.frontend.from_pytorch(script_module, shape_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Relay VM 编译\n",
    "\n",
    "注:目前只支持 CPU target。对于 x86 target，由于在 torchvision rcnn 模型中存在较大的 dense 算子，因此强烈推荐使用 Intel MKL 和 Intel OpenMP 构建 TVM 以获得最佳性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"-libs=mkl\" to get best performance on x86 target.\n",
    "# For x86 machine supports AVX512, the complete target is\n",
    "# \"llvm -mcpu=skylake-avx512 -libs=mkl\"\n",
    "target = \"llvm\"\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    vm_exec = relay.vm.compile(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Relay VM 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ctx = tvm.cpu()\n",
    "vm = VirtualMachine(vm_exec, ctx)\n",
    "vm.set_input(\"main\", **{input_name: img})\n",
    "tvm_res = vm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.7 ms ± 2.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "vm.set_input(\"main\", **{input_name: img})\n",
    "tvm_res = vm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取得分大于 0.6 的 box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 4 valid boxes\n"
     ]
    }
   ],
   "source": [
    "score_threshold = 0.6\n",
    "boxes = tvm_res[0].asnumpy().tolist()\n",
    "valid_boxes = []\n",
    "for i, score in enumerate(tvm_res[1].asnumpy().tolist()):\n",
    "    if score > score_threshold:\n",
    "        valid_boxes.append(boxes[i])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Get {len(valid_boxes)} valid boxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证 TVM 后端的推理输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch_res = script_module(torch.from_numpy(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with TVM Runtime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(torch_res)):\n",
    "    torch.testing.assert_allclose(torch_res[i], tvm_res[i].asnumpy(), rtol=1e-4, atol=1e-4)\n",
    "\n",
    "print(\"Exported model has been tested with TVM Runtime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
